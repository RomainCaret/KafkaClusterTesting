{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install azureml-pipeline"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters of the cpu\n",
        "vm_size = \"Standard_DS3_v2\"\n",
        "vm_priority = \"Dedicated\"\n",
        "number_of_max_instances = 4\n",
        "\n",
        "# Parameters of the broker\n",
        "brokerAddress = \"\\'20.8.72.226\\'\"\n",
        "machineTypeKafka = \"DS2_v2\"\n",
        "\n",
        "# Parameter of machine\n",
        "nb_instances_per_cpu = 4 # Has to be equal to the number of max instances\n",
        "nb_compute = 8 # Number of virtual machines for production and consumption\n",
        "\n",
        "# Calculated parameters for number of machines needed\n",
        "cpu_all = 2 * nb_compute + 1 # 1 for the manager"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute, PipelineJobSettings\n",
        "import datetime\n",
        "from azure.identity import DefaultAzureCredential\n",
        "import os\n",
        "from azure.ai.ml import MLClient\n",
        "from azureml.core import Workspace\n",
        "import time\n",
        "# the dsl decorator tells the sdk that we are defining an Azure ML pipeline\n",
        "from azure.ai.ml import dsl\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "credential = DefaultAzureCredential()\n",
        "nb_compute_prod_cons = nb_compute\n",
        "\n",
        "# Execute the script\n",
        "%run setenv.py\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id= os.environ['subscription_id'],\n",
        "    resource_group_name= os.environ['resource_group'],\n",
        "    workspace_name= os.environ['workspace_name']\n",
        ")\n",
        "\n",
        "# Function to create a cluster-------------------------------------------------\n",
        "\n",
        "def create_cluster(ml_client, vm_size, vm_priority, number_of_max_instances):\n",
        "    # Create a unique name for the cluster\n",
        "    cpu_compute_target = \"cpu-cluster-kafka-\" + datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "\n",
        "    cpu_cluster = AmlCompute(\n",
        "            name=cpu_compute_target,\n",
        "            # Azure ML Compute is the on-demand VM service\n",
        "            type=\"amlcompute\",\n",
        "            # VM Family\n",
        "            size=vm_size,\n",
        "            # Minimum running nodes when there is no job running\n",
        "            min_instances=0,\n",
        "            # Nodes in cluster\n",
        "            max_instances=number_of_max_instances,\n",
        "            # How many seconds will the node running after the job termination\n",
        "            idle_time_before_scale_down=180,\n",
        "            # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        "            tier=vm_priority,\n",
        "        )\n",
        "        # Now, we pass the object to MLClient's create_or_update method\n",
        "    ml_client.compute.begin_create_or_update(cpu_cluster)\n",
        "    return ml_client.compute.get(cpu_compute_target)\n",
        "\n",
        "# End of the function to create a cluster--------------------------------------\n",
        "\n",
        "# Create the clusters---------------------------------------------------------\n",
        "\n",
        "cpu_list_available = []\n",
        "\n",
        "for _ in range(cpu_all):\n",
        "    cpu = create_cluster(ml_client, vm_size, vm_priority, number_of_max_instances)\n",
        "    cpu_list_available.append(cpu)\n",
        "    time.sleep(1)\n",
        "\n",
        "time.sleep(5)\n",
        "\n",
        "# End of the creation of the clusters-----------------------------------------\n",
        "\n",
        "# Define the pipelines--------------------------------------------------------\n",
        "\n",
        "@dsl.pipeline(\n",
        "    name=\"Manager\"+machineTypeKafka,\n",
        "    description=\"Manager pipeline\",\n",
        "    default_compute_target=cpu_list_available.pop().name,\n",
        ")\n",
        "def pipeline_manager():\n",
        "    manager = ml_client.components.get(\"manager\")\n",
        "\n",
        "    manager = manager(\n",
        "            brokerAddress=brokerAddress,\n",
        "            nb_consumers_producers=(nb_compute_prod_cons)*nb_instances_per_cpu,\n",
        "    )\n",
        "    return {}\n",
        "\n",
        "@dsl.pipeline(\n",
        "    name=\"Consumer\"+machineTypeKafka,\n",
        "    description=\"Consumer pipeline\",\n",
        "    default_compute_target=cpu_list_available[0].name,\n",
        ")\n",
        "def pipeline_consumer():\n",
        "    consumer = ml_client.components.get(\"consumer\")\n",
        "\n",
        "    for i in range(nb_instances_per_cpu):\n",
        "        consumer = consumer(\n",
        "            num_consumer = str(i),\n",
        "            num_machine = str(nb_compute_prod_cons),\n",
        "            brokerAddress=brokerAddress,\n",
        "        )\n",
        "\n",
        "    return {}\n",
        "\n",
        "@dsl.pipeline(\n",
        "    name=\"Producer\"+machineTypeKafka,\n",
        "    description=\"Producer pipeline\",\n",
        "    default_compute_target=cpu_list_available[0].name,\n",
        ")\n",
        "def pipeline_producer():\n",
        "    producer = ml_client.components.get(\"producer\")\n",
        "\n",
        "    for i in range(nb_instances_per_cpu):\n",
        "        producer = producer(\n",
        "            num_producer = str(i),\n",
        "            num_machine = str(nb_compute_prod_cons),\n",
        "            brokerAddress=brokerAddress,\n",
        "            machineKafka=machineTypeKafka,\n",
        "        )\n",
        "\n",
        "    return {}\n",
        "\n",
        "# End of the definition of the pipelines--------------------------------------\n",
        "\n",
        "# Create the pipelines--------------------------------------------------------\n",
        "\n",
        "pipeline_manager = pipeline_manager()\n",
        "\n",
        "while nb_compute_prod_cons > 0:\n",
        "    nb_compute_prod_cons -= 1\n",
        "    # Create the consumer pipeline\n",
        "    pipeline_cons = pipeline_consumer()\n",
        "\n",
        "    # Set the compute target and pop it from the list\n",
        "    pipeline_cons.settings = PipelineJobSettings(\n",
        "        default_compute=cpu_list_available.pop().name\n",
        "    )\n",
        "\n",
        "    # Submit the pipeline\n",
        "    ml_client.jobs.create_or_update(\n",
        "        pipeline_cons,\n",
        "        # Project's name\n",
        "        experiment_name=\"consumer\"+machineTypeKafka+str(nb_compute_prod_cons),\n",
        "    )\n",
        "\n",
        "    # Create the producer pipeline\n",
        "    pipeline_prod = pipeline_producer()\n",
        "\n",
        "    # Set the compute target and pop it from the list\n",
        "    pipeline_prod.settings = PipelineJobSettings(\n",
        "        default_compute=cpu_list_available.pop().name\n",
        "    )\n",
        "\n",
        "    # Submit the pipeline\n",
        "    ml_client.jobs.create_or_update(\n",
        "        pipeline_prod,\n",
        "        # Project's name\n",
        "        experiment_name=\"producer\"+machineTypeKafka+str(nb_compute_prod_cons),\n",
        "    )\n",
        "\n",
        "    # Decrease the number of consumers and producers\n",
        "    \n",
        "\n",
        "# End of the creation of the pipelines----------------------------------------\n",
        "\n",
        "# Create the manager pipeline-------------------------------------------------\n",
        "\n",
        "\n",
        "# Submit the pipeline\n",
        "ml_client.jobs.create_or_update(\n",
        "    pipeline_manager,\n",
        "    # Project's name\n",
        "    experiment_name=\"manager\"+machineTypeKafka,\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The history saving thread hit an unexpected error (OperationalError('no such table: history')).History will not be written to the database.\n"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nb_compute' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/azureuser/cloudfiles/code/Users/romain.caret/kafka-aiops/launchExperiments.ipynb Cell 3\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38623533373463352d386239382d343566622d626439362d3764356134636534653532372f7265736f7572636547726f7570732f72672d7362782d61696f70732f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f726f6d61696e2d6d6c626f782f636f6d70757465732f746573742d6e626b/home/azureuser/cloudfiles/code/Users/romain.caret/kafka-aiops/launchExperiments.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m ws \u001b[39m=\u001b[39m Workspace\u001b[39m.\u001b[39mfrom_config()\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38623533373463352d386239382d343566622d626439362d3764356134636534653532372f7265736f7572636547726f7570732f72672d7362782d61696f70732f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f726f6d61696e2d6d6c626f782f636f6d70757465732f746573742d6e626b/home/azureuser/cloudfiles/code/Users/romain.caret/kafka-aiops/launchExperiments.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m credential \u001b[39m=\u001b[39m DefaultAzureCredential()\n\u001b[0;32m---> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38623533373463352d386239382d343566622d626439362d3764356134636534653532372f7265736f7572636547726f7570732f72672d7362782d61696f70732f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f726f6d61696e2d6d6c626f782f636f6d70757465732f746573742d6e626b/home/azureuser/cloudfiles/code/Users/romain.caret/kafka-aiops/launchExperiments.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m nb_compute_prod_cons \u001b[39m=\u001b[39m nb_compute\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38623533373463352d386239382d343566622d626439362d3764356134636534653532372f7265736f7572636547726f7570732f72672d7362782d61696f70732f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f726f6d61696e2d6d6c626f782f636f6d70757465732f746573742d6e626b/home/azureuser/cloudfiles/code/Users/romain.caret/kafka-aiops/launchExperiments.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Execute the script\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38623533373463352d386239382d343566622d626439362d3764356134636534653532372f7265736f7572636547726f7570732f72672d7362782d61696f70732f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f726f6d61696e2d6d6c626f782f636f6d70757465732f746573742d6e626b/home/azureuser/cloudfiles/code/Users/romain.caret/kafka-aiops/launchExperiments.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mrun\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msetenv.py\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nb_compute' is not defined"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1678397375022
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "azureml_py38",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
      }
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}