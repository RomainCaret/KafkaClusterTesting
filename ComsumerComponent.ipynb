{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1.2 Writing our component\n",
        "First of all, we are creating a yml file. This file will be a description of our azure ml component. It explains how this component works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "component_dir = \"./components\"\n",
        "os.makedirs(component_dir, exist_ok=True)\n",
        "\n",
        "src_dir = \"./components/src_consumer\"\n",
        "os.makedirs(src_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./components/consumer.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile $component_dir/consumer.yml\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: consumer\n",
        "display_name: consumer\n",
        "is_deterministic: false\n",
        "version: 0.51\n",
        "type: command\n",
        "inputs:\n",
        "  num_consumer:\n",
        "    type: string\n",
        "    description: \"numero du consumer\"\n",
        "    default: \"Consumer\"\n",
        "  num_machine:\n",
        "    type: string\n",
        "    description: \"numero de la machine\"\n",
        "    default: \"Machine\"\n",
        "  brokerAddress:\n",
        "    type: string\n",
        "    description: \"Broker address\"\n",
        "code: ./src_consumer\n",
        "environment: azureml:kafka-custom-env@latest\n",
        "command: >-\n",
        "  python consumer.py\n",
        "  --num_consumer ${{inputs.num_consumer}}\n",
        "  --num_machine ${{inputs.num_machine}}\n",
        "  --brokerAddress ${{inputs.brokerAddress}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./components/src_consumer/consumer.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {src_dir}/consumer.py\n",
        "from kafka import KafkaConsumer\n",
        "from kafka import KafkaProducer\n",
        "import argparse\n",
        "import time\n",
        "import mlflow\n",
        "import json\n",
        "import time\n",
        "from threading import Thread\n",
        "import psutil\n",
        "import platform\n",
        "import cpuinfo\n",
        "import numpy as np\n",
        "\n",
        "def create_consumer_proc_data():\n",
        "    proc = {}\n",
        "    uname = platform.uname()\n",
        "    proc['system'] = uname.system\n",
        "    proc['processor'] = uname.processor\n",
        "    proc['cpu_brand'] = cpuinfo.get_cpu_info()['brand_raw']\n",
        "    proc['cpu_hz'] = cpuinfo.get_cpu_info()['hz_actual_friendly']\n",
        "    proc['cpu_cores'] = psutil.cpu_count(logical=False)\n",
        "    proc['cpu_cores_total'] = psutil.cpu_count(logical=True)\n",
        "    svmem = psutil.virtual_memory()\n",
        "    proc['ram_total'] = svmem.total\n",
        "    return proc\n",
        "\n",
        "\n",
        "def consume_messages(brokerAddress, proc_data, name):\n",
        "    brokerAddress = brokerAddress.split(\" \")\n",
        "    for i in range(len(brokerAddress)):\n",
        "        brokerAddress[i] = brokerAddress[i] + \":9094\"\n",
        "    print(\"brokerAddress : \", brokerAddress)\n",
        "\n",
        "    consumer = KafkaConsumer(\n",
        "            bootstrap_servers=brokerAddress,\n",
        "            api_version=(0, 10),)\n",
        "\n",
        "    consumer.subscribe(['consumer-write'+name, 'topic-aiops'+name, 'consumer-end'+name])\n",
        "\n",
        "    producer = KafkaProducer(\n",
        "        bootstrap_servers=brokerAddress,\n",
        "        api_version=(0, 10),\n",
        "    )\n",
        "\n",
        "    data_saved = False\n",
        "    listTime = []\n",
        "    producer.send(\"manager-consumer\", json.dumps({\"consumer-start\": \"start consumer\"}).encode(\"utf-8\"))\n",
        "\n",
        "    for message in consumer:\n",
        "        # Check the topic of the message\n",
        "        if message.topic == \"topic-aiops\"+name:\n",
        "            if not data_saved:\n",
        "                data = json.loads(message.value.decode(\"utf-8\"))\n",
        "                data_saved = True\n",
        "            diff = time.time() - json.loads(message.value.decode(\"utf-8\"))[\"timestamp\"]\n",
        "            listTime.append(diff)\n",
        "        elif message.topic == \"consumer-write\"+name:\n",
        "            producer.send(\"debug\", json.dumps({\"consumer-write\": \"write data\"}).encode(\"utf-8\"))\n",
        "            if len(listTime) > 0:\n",
        "                # Write data in csv with the median of the list\n",
        "                data_summarized = {}\n",
        "                data_summarized[\"machine_kafka\"] = data[\"machine_kafka\"]\n",
        "                data_summarized[\"batch_size\"] = data[\"batch_size\"]\n",
        "                data_summarized[\"nb_messages\"] = len(listTime)\n",
        "                data_summarized[\"time\"] = np.median(listTime)\n",
        "                producer.send(\"manager-consumer\", json.dumps(data_summarized).encode(\"utf-8\"))\n",
        "                listTime = []\n",
        "                data_saved = False\n",
        "            else:\n",
        "                producer.send(\"debug\", json.dumps({\"error in consumer\": \"no data to write\"}).encode(\"utf-8\"))\n",
        "        elif message.topic == \"consumer-end\"+name:\n",
        "            print(\"End of consumer\")\n",
        "            break\n",
        "        else :\n",
        "            producer.send(\"debug\", json.dumps({\"error in consumer\": \"topic not found : \" + message.topic}).encode(\"utf-8\"))\n",
        "    consumer.close()\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function of the script.\"\"\"\n",
        "\n",
        "    # input and output arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--num_consumer\", type=str, help=\"numero du consumer\")\n",
        "    parser.add_argument(\"--num_machine\", type=str, help=\"numero de la machine\")\n",
        "    parser.add_argument(\"--brokerAddress\", type=str, help=\"Broker address\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "   \n",
        "    name = args.num_machine + \"-\" + args.num_consumer\n",
        "\n",
        "    # Start Logging\n",
        "    mlflow.start_run()\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Set the data of the consumer\n",
        "    proc_data = create_consumer_proc_data()\n",
        "    \n",
        "    # create a new thread\n",
        "    thread = Thread(target=consume_messages, args=(args.brokerAddress, proc_data, name))\n",
        "    # start the thread\n",
        "    thread.start()\n",
        "\n",
        "    thread.join()\n",
        "    \n",
        "    # Stop Logging\n",
        "    mlflow.end_run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Go into the right folder\n",
        "```\n",
        "$ cd kafka\n",
        "```\n",
        "* Execute the setenv.sh script that will setup variables environment\n",
        "```\n",
        "$ source setenv.sh\n",
        "```\n",
        "* Go into the components folder \n",
        "```\n",
        "$ cd components\n",
        "```\n",
        "* Login Azure with this command\n",
        "```\n",
        "$ az login --tenant $tenant_id\n",
        "```\n",
        "* After you successfuly login, set the right subscription ID you are currently using in Microsoft Azure Machine learning Studio.\n",
        "```\n",
        "$ az account set --subscription $subscription_id\n",
        "```\n",
        "* Set your workspace and resource group\n",
        "```\n",
        "$ az configure --defaults workspace=$workspace_name group=$resource_group\n",
        "```\n",
        "* You are now perfectly set up and can create a component with this command with the .yml file that we created earlier :\n",
        "```\n",
        "$ az ml component create --file consumer.yml\n",
        "```\n",
        "* It should display a JSON with informations of the component you just created"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK V2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
